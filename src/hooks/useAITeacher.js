import { create } from 'zustand';

// âœ… Auto-detect backend (use same machine IP if deployed)
const FLASK_BASE_URL = 'http://127.0.0.1:5000'; // keep same if running locally

// --- ðŸ› ï¸ UPDATE HERE: Add "rpm" to the list of teachers ---
export const teachers = ["female", "male", "rpm"]; 

// --- NEW: Pre-defined lesson scripts ---
// We add all our pre-defined English lessons here.
// The backend /api/tts will speak this text using the selected voice.
const predefinedLessons = {
Â  abc: "Let's learn our ABCs! A, B, C, D,! say again A, B, C, D wow nice try can you want again !",
Â  fruits: "Let's Learn the Fruits Names! Â Apples, Bananas, Oranges, and Grapes!",
Â  days: "Let's learn the days of the week! Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday."
};
// --- End New ---

export const useAITeacher = create((set, get) => ({
Â  Â  messages: [],
Â  Â  currentMessage: null,
Â  Â  teacher: teachers[0],
Â  Â  setTeacher: (teacher) => {
Â  Â  Â  Â  set(() => ({
Â  Â  Â  Â  Â  Â  teacher,
Â  Â  Â  Â  Â  Â  messages: get().messages.map((message) => {
Â  Â  Â  Â  Â  Â  Â  Â  // Reset visemes/audio when teacher changes
Â  Â  Â  Â  Â  Â  Â  Â  message.audioPlayer = null;
Â  Â  Â  Â  Â  Â  Â  Â  message.visemes = [];
Â  Â  Â  Â  Â  Â  Â  Â  return message;
Â  Â  Â  Â  Â  Â  }),
Â  Â  Â  Â  }));
Â  Â  },
Â  Â  classroom: "default",
Â  Â  setClassroom: (classroom) => set({ classroom }),

Â  Â  loading: false,
Â  Â  furigana: false,
Â  Â  setFurigana: (furigana) => set({ furigana }),

Â  Â  english: true,
Â  Â  setEnglish: (english) => set({ english }),

Â  Â  speech: "simple",
Â  Â  setSpeech: (speech) => set({ speech }),

Â  Â  // ------------------------------------------------
Â  Â  // ðŸš€ Main Function: Ask AI (Unchanged)
Â  Â  // ------------------------------------------------
Â  Â  askAI: async (question) => {
Â  Â  Â  Â  if (!question) return;

Â  Â  Â  Â  const message = { question, id: get().messages.length };
Â  Â  Â  Â  set({ loading: true });

Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const speechLevel = get().speech;

Â  Â  Â  Â  Â  Â  const res = await fetch(
Â  Â  Â  Â  Â  Â  Â  Â  `${FLASK_BASE_URL}/api/ai?question=${encodeURIComponent(question)}&speech=${speechLevel}`,
Â  Â  Â  Â  Â  Â  Â  Â  { headers: { "Accept": "application/json" } }
Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  if (!res.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error("AI API Call Failed:", res.status, await res.text());
Â  Â  Â  Â  Â  Â  Â  Â  // --- ADDED: Create a simple fallback message ---
Â  Â  Â  Â  Â  Â  Â  Â  message.answer = { text: "Sorry, I had a problem thinking. Please try again!" };
Â  Â  Â  Â  Â  Â  Â  Â  set({ loading: false, currentMessage: message, messages: [...get().messages, message] });
Â  Â  Â  Â  Â  Â  Â  Â  get().playMessage(message); // Play the error message
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  Â  Â  // ---
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const data = await res.json();
Â  Â  Â  Â  Â  Â  message.answer = data;
Â  Â  Â  Â  Â  Â  message.speech = speechLevel;

Â  Â  Â  Â  Â  Â  set({
Â  Â  Â  Â  Â  Â  Â  Â  currentMessage: message,
Â  Â  Â  Â  Â  Â  Â  Â  messages: [...get().messages, message],
Â  Â  Â  Â  Â  Â  Â  Â  loading: false,
Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  get().playMessage(message);
Â  Â  Â  Â  } catch (err) {
Â  Â  Â  Â  Â  Â  console.error("AI Request Error:", err);
Â  Â  Â  Â  Â  Â  set({ loading: false });
Â  Â  Â  Â  }
Â  Â  },

Â  Â  // ------------------------------------------------
Â  Â  // ðŸ—£ï¸ Play Message (TTS + Viseme Sync)
Â  Â  // ------------------------------------------------
Â  Â  playMessage: async (message) => {
Â  Â  Â  Â  set({ currentMessage: message });

Â  Â  Â  Â  if (!message.audioPlayer) {
Â  Â  Â  Â  Â  Â  set({ loading: true });

Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  // --- *** FIX: This now works for AI *and* pre-defined lessons *** ---
Â  Â  Â  Â  Â  Â  Â  Â  const textToSpeak = message.answer.text // Check for pre-defined text first
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ? message.answer.text 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Otherwise, get text from the (Japanese) AI response
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  : message.answer.japanese.map((word) => word.word).join(" ");
Â  Â  Â  Â  Â  Â  Â  Â  // --- *** END FIX *** ---

Â  Â  Â  Â  Â  Â  Â  Â  const audioRes = await fetch(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  `${FLASK_BASE_URL}/api/tts?teacher=${get().teacher}&text=${encodeURIComponent(textToSpeak)}`,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  { headers: { "Accept": "audio/mpeg" } }
Â  Â  Â  Â  Â  Â  Â  Â  );

Â  Â  Â  Â  Â  Â  Â  Â  if (!audioRes.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error("TTS API Call Failed:", audioRes.status, await audioRes.text());
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  set({ loading: false, currentMessage: null });
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  // âœ… FIX: Ensure viseme header parsed safely
Â  Â  Â  Â  Â  Â  Â  Â  const visemesHeader = audioRes.headers.get("Visemes");
Â  Â  Â  Â  Â  Â  Â  Â  let visemes = [];
Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  visemes = JSON.parse(visemesHeader || "[]");
Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn("Viseme parse failed:", e);
Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  const audioBlob = await audioRes.blob();
Â  Â  Â  Â  Â  Â  Â  Â  const audioUrl = URL.createObjectURL(audioBlob);
Â  Â  Â  Â  Â  Â  Â  Â  const audioPlayer = new Audio(audioUrl);

Â  Â  Â  Â  Â  Â  Â  Â  message.visemes = visemes;
Â  Â  Â  Â  Â  Â  Â  Â  message.audioPlayer = audioPlayer;

Â  Â  Â  Â  Â  Â  Â  Â  audioPlayer.onended = () => set({ currentMessage: null });

Â  Â  Â  Â  Â  Â  Â  Â  set({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  loading: false,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  messages: get().messages.map((m) => (m.id === message.id ? message : m)),
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  } catch (err) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error("TTS Request Error:", err);
Â  Â  Â  Â  Â  Â  Â  Â  set({ loading: false, currentMessage: null });
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  // Play audio
Â  Â  Â  Â  if (message.audioPlayer) {
Â  Â  Â  Â  Â  Â  message.audioPlayer.currentTime = 0;
Â  Â  Â  Â  Â  Â  message.audioPlayer.play();
Â  Â  Â  Â  }
Â  Â  },

Â  Â  // ------------------------------------------------
Â  Â  // ðŸ›‘ Stop Message (Unchanged)
Â  Â  // ------------------------------------------------
Â  Â  stopMessage: (message) => {
Â  Â  Â  Â  if (message.audioPlayer) {
Â  Â  Â  Â  Â  Â  message.audioPlayer.pause();
Â  Â  Â  Â  Â  Â  message.audioPlayer.currentTime = 0;
Â  Â  Â  Â  }
Â  Â  Â  Â  set({ currentMessage: null });
Â  Â  },

Â  Â  // --- *** NEW: Function to play pre-defined lessons *** ---
Â  Â  playPredefinedLesson: (lessonKey) => {
Â  Â  Â  Â  const text = predefinedLessons[lessonKey];
Â  Â  Â  Â  if (!text) {
Â  Â  Â  Â  Â  Â  console.error(`Lesson "${lessonKey}" not found.`);
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  // Stop any current message
Â  Â  Â  Â  if (get().currentMessage) {
Â  Â  Â  Â  Â  Â  get().stopMessage(get().currentMessage);
Â  Â  Â  Â  }

Â  Â  Â  Â  // Create a message object that mimics the AI response structure
Â  Â  Â  Â  const message = {
Â  Â  Â  Â  Â  Â  id: lessonKey + Date.now(),
Â  Â  Â  Â  Â  Â  question: `Play lesson: ${lessonKey}`,
Â  Â  Â  Â  Â  Â  answer: {
Â  Â  Â  Â  Â  Â  Â  Â  text: text, // This is the pre-defined English text
Â  Â  Â  Â  Â  Â  Â  Â  // Add dummy data for other fields to prevent errors
Â  Â  Â  Â  Â  Â  Â  Â  japanese: [{ word: text, reading: "" }], 
Â  Â  Â  Â  Â  Â  Â  Â  grammarBreakdown: [],
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  speech: "simple",
Â  Â  Â  Â  Â  Â  audioPlayer: null, 
Â  Â  Â  Â  Â  Â  visemes: [],
Â  Â  Â  Â  };

Â  Â  Â  Â  // Call playMessage with our pre-defined text
Â  Â  Â  Â  get().playMessage(message);
Â  Â  },
Â  Â  // --- *** END NEW Function *** ---
}));